{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Youtuber.ipynb","provenance":[],"authorship_tag":"ABX9TyNAxLgIDSOg3dY/g9Whd1Mw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"me0bBhvVPT0Q","executionInfo":{"status":"ok","timestamp":1656439528087,"user_tz":240,"elapsed":153,"user":{"displayName":"Luv Khandelwal","userId":"05912880675308525175"}}},"outputs":[],"source":["# https://youtu.be/tepxdcepTbY\n","\"\"\"\n","@author: Sreenivas Bhattiprolu\n","Code tested on Tensorflow: 2.2.0\n","    Keras: 2.4.3\n","dataset: https://finance.yahoo.com/quote/GE/history/\n","Also try S&P: https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC\n","\"\"\"\n","\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Dense, Dropout\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","import seaborn as sns\n","#from datetime import datetime\n","\n"]},{"cell_type":"code","source":["#Read the csv file\n","df = pd.read_csv('GE.csv')\n","print(df.head()) #7 columns, including the Date. \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8smSNtOPY9A","executionInfo":{"status":"ok","timestamp":1656439536143,"user_tz":240,"elapsed":145,"user":{"displayName":"Luv Khandelwal","userId":"05912880675308525175"}},"outputId":"a87d2a62-a7c6-4213-d2cc-47a3c20eb4ec"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["         Date        Open        High         Low       Close   Adj Close  \\\n","0  2021-06-28  105.279999  105.360001  102.320000  103.120003  102.734680   \n","1  2021-06-29  104.480003  105.839996  103.680000  104.720001  104.328690   \n","2  2021-06-30  105.199997  108.239998  104.400002  107.680000  107.277634   \n","3  2021-07-01  108.639999  109.040001  106.879997  107.839996  107.437027   \n","4  2021-07-02  108.320000  108.320000  106.480003  106.879997  106.480606   \n","\n","    Volume  \n","0  7723450  \n","1  8649650  \n","2  8568975  \n","3  5836638  \n","4  4144988  \n"]}]},{"cell_type":"code","source":["\n","#Separate dates for future plotting\n","train_dates = pd.to_datetime(df['Date'])\n","print(train_dates.tail(15)) #Check last few dates. \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKMi3B9fPdUP","executionInfo":{"status":"ok","timestamp":1656439801206,"user_tz":240,"elapsed":131,"user":{"displayName":"Luv Khandelwal","userId":"05912880675308525175"}},"outputId":"7eed4484-9edd-4e88-90b3-25d0f2fa643e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["238   2022-06-07\n","239   2022-06-08\n","240   2022-06-09\n","241   2022-06-10\n","242   2022-06-13\n","243   2022-06-14\n","244   2022-06-15\n","245   2022-06-16\n","246   2022-06-17\n","247   2022-06-21\n","248   2022-06-22\n","249   2022-06-23\n","250   2022-06-24\n","251   2022-06-27\n","252   2022-06-28\n","Name: Date, dtype: datetime64[ns]\n"]}]},{"cell_type":"code","source":["\n","#Variables for training\n","cols = list(df)[1:6]\n","#Date and volume columns are not used in training. \n","print(cols) #['Open', 'High', 'Low', 'Close', 'Adj Close']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Omrj6goePiIJ","executionInfo":{"status":"ok","timestamp":1656439806643,"user_tz":240,"elapsed":564,"user":{"displayName":"Luv Khandelwal","userId":"05912880675308525175"}},"outputId":"e02d95c1-3adb-4263-e2c4-079b4ce35aa1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['Open', 'High', 'Low', 'Close', 'Adj Close']\n"]}]},{"cell_type":"code","source":["\n","#New dataframe with only training data - 5 columns\n","df_for_training = df[cols].astype(float)\n","\n","# df_for_plot=df_for_training.tail(5000)\n","# df_for_plot.plot.line()\n","\n","#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n","# normalize the dataset\n","scaler = StandardScaler()\n","scaler = scaler.fit(df_for_training)\n","df_for_training_scaled = scaler.transform(df_for_training)\n","\n","\n","#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. \n","#In this example, the n_features is 5. We will make timesteps = 14 (past days data used for training). \n","\n","#Empty lists to be populated using formatted training data\n","trainX = []\n","trainY = []\n","\n","n_future = 1   # Number of days we want to look into the future based on the past days.\n","n_past = 14  # Number of past days we want to use to predict the future.\n","\n","#Reformat input data into a shape: (n_samples x timesteps x n_features)\n","#In my example, my df_for_training_scaled has a shape (12823, 5)\n","#12823 refers to the number of data points and 5 refers to the columns (multi-variables).\n","for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n","    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n","    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n","\n","trainX, trainY = np.array(trainX), np.array(trainY)\n","\n","print('trainX shape == {}.'.format(trainX.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUiliShsPlCv","executionInfo":{"status":"ok","timestamp":1656439830404,"user_tz":240,"elapsed":136,"user":{"displayName":"Luv Khandelwal","userId":"05912880675308525175"}},"outputId":"57440583-ceb1-4993-a6e8-68ac861dfcc1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["trainX shape == (239, 14, 5).\n"]}]},{"cell_type":"code","source":["print('trainY shape == {}.'.format(trainY.shape))"],"metadata":{"id":"yeMgALYPgeuw","executionInfo":{"status":"ok","timestamp":1656439845296,"user_tz":240,"elapsed":167,"user":{"displayName":"Luv Khandelwal","userId":"05912880675308525175"}},"outputId":"f24ba49b-e418-49da-e45d-feb8f6b4b8e4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["trainY shape == (239, 1).\n"]}]},{"cell_type":"code","source":["#In my case, trainX has a shape (12809, 14, 5). \n","#12809 because we are looking back 14 days (12823 - 14 = 12809). \n","#Remember that we cannot look back 14 days until we get to the 15th day. \n","#Also, trainY has a shape (12809, 1). Our model only predicts a single value, but \n","#it needs multiple variables (5 in my example) to make this prediction. \n","#This is why we can only predict a single day after our training, the day after where our data ends.\n","#To predict more days in future, we need all the 5 variables which we do not have. \n","#We need to predict all variables if we want to do that. \n","\n","# define the Autoencoder model\n","\n","model = Sequential()\n","model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n","model.add(LSTM(32, activation='relu', return_sequences=False))\n","model.add(Dropout(0.2))\n","model.add(Dense(trainY.shape[1]))\n","\n","model.compile(optimizer='adam', loss='mse')\n","model.summary()\n"],"metadata":{"id":"gMiszDShPqBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fit the model\n","history = model.fit(trainX, trainY, epochs=5, batch_size=16, validation_split=0.1, verbose=1)\n","\n","plt.plot(history.history['loss'], label='Training loss')\n","plt.plot(history.history['val_loss'], label='Validation loss')\n","plt.legend()\n","\n","#Predicting...\n","#Libraries that will help us extract only business days in the US.\n","#Otherwise our dates would be wrong when we look back (or forward).  \n","from pandas.tseries.holiday import USFederalHolidayCalendar\n","from pandas.tseries.offsets import CustomBusinessDay\n","us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n","#Remember that we can only predict one day in future as our model needs 5 variables\n","#as inputs for prediction. We only have all 5 variables until the last day in our dataset.\n","n_past = 16\n","n_days_for_prediction=15  #let us predict past 15 days\n","\n","predict_period_dates = pd.date_range(list(train_dates)[-n_past], periods=n_days_for_prediction, freq=us_bd).tolist()\n","print(predict_period_dates)"],"metadata":{"id":"6Cq7I6dBPuhG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#Make prediction\n","prediction = model.predict(trainX[-n_days_for_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n","\n","#Perform inverse transformation to rescale back to original range\n","#Since we used 5 variables for transform, the inverse expects same dimensions\n","#Therefore, let us copy our values 5 times and discard them after inverse transform\n","prediction_copies = np.repeat(prediction, df_for_training.shape[1], axis=-1)\n","y_pred_future = scaler.inverse_transform(prediction_copies)[:,0]\n","\n","\n","# Convert timestamp to date\n","forecast_dates = []\n","for time_i in predict_period_dates:\n","    forecast_dates.append(time_i.date())\n","    \n","df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Open':y_pred_future})\n","df_forecast['Date']=pd.to_datetime(df_forecast['Date'])\n","\n","\n","original = df[['Date', 'Open']]\n","original['Date']=pd.to_datetime(original['Date'])\n","original = original.loc[original['Date'] >= '2020-5-1']\n","\n","sns.lineplot(original['Date'], original['Open'])\n","sns.lineplot(df_forecast['Date'], df_forecast['Open'])"],"metadata":{"id":"0ivLPzlXP1D9"},"execution_count":null,"outputs":[]}]}